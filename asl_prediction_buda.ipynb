{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pybuda\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"dyllanesl/ASL_Classifier\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"dyllanesl/ASL_Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt0 = pybuda.TTDevice(\n",
    "    name=\"tt_device_0\",  # here we can give our device any name we wish, for tracking purposes\n",
    "    arch=pybuda.BackendDevice.Grayskull\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create module\n",
    "pybuda_module = pybuda.PyTorchModule(\n",
    "    name = \"asl_model\",  # give the module a name, this will be used for tracking purposes\n",
    "    module=model  # specify the model that is being targeted for compilation\n",
    ")\n",
    "\n",
    "# Place module on device\n",
    "tt0.place_module(module=pybuda_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration raulit04--ASL_Dataset1-d033ce9363c88848\n",
      "Reusing dataset parquet (/home/user/.cache/huggingface/datasets/raulit04___parquet/raulit04--ASL_Dataset1-d033ce9363c88848/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n",
      "100%|██████████| 1/1 [00:00<00:00, 571.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "dataset = load_dataset('raulit04/ASL_Dataset1')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from labels to IDs\n",
    "label_list = dataset.unique('label')\n",
    "\n",
    "label_to_id = {label: idx for idx, label in enumerate(label_list)}\n",
    "id_to_label = {idx: label for idx, label in enumerate(label_to_id)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set PyBUDA configuration parameters\n",
    "# STEP 1 : Set PyBuda configuration parameters\n",
    "import os\n",
    "# STEP 1 : Set PyBuda configuration parameters\n",
    "compiler_cfg = pybuda.config._get_global_compiler_config()\n",
    "compiler_cfg.balancer_policy = \"Ribbon\"\n",
    "compiler_cfg.default_df_override = pybuda.DataFormat.Float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_image(image: Image):\n",
    "    image.convert(\"RGB\")\n",
    "    processed_tensor = processor(images=image, return_tensors='pt')\n",
    "    return processed_tensor['pixel_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = pybuda_module.run(input_tensor)  # executes compilation (if first time) + runtime\n",
    "# print('output: ', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_given_tensor(input_tensor):\n",
    "    tt0.push_to_inputs((input_tensor,))\n",
    "    # output = pybuda_module.run(input_tensor)  # executes compilation (if first time) + runtime\n",
    "    output_q = pybuda.run_inference()\n",
    "    output = output_q.get()\n",
    "    output_tensor = output[0].value()\n",
    "    pred = output_tensor.argmax(-1).item()\n",
    "    return id_to_label[pred]\n",
    "    print('\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n",
    "    print('output: ', output_tensor)\n",
    "    print('\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_length = len(dataset['image'])\n",
    "correct = 0\n",
    "for i, (image, label) in enumerate(zip(dataset['image'], dataset['label'])):\n",
    "    if i == 0:\n",
    "        print('image: ')\n",
    "        display(image)\n",
    "    readied_tensor = setup_image(image)\n",
    "    guessed_label = get_prediction_given_tensor(readied_tensor)\n",
    "    \n",
    "    if i < 5:\n",
    "        print('actual label: ', label, ' guessed label: ', guessed_label)\n",
    "    if i ==5:\n",
    "        print(\"you get the deal. I'll just print out the accuracy\")\n",
    "    correct += 1 if label == guessed_label else 0\n",
    "    # break\n",
    "\n",
    "print('accuracy: ', correct/dataset_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 23:59:43.473 | DEBUG    | pybuda.run.impl:_run_forward:644 - Running concurrent device forward: TTDevice 'tt_device_0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-02 23:59:43.479\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mRuntime        \u001b[0m - Running program 'run_fwd_0' with params [(\"$p_loop_count\", \"1\")]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 23:59:43.478 | DEBUG    | pybuda.device:run_next_command:429 - Received RUN_FORWARD command on TTDevice 'tt_device_0' / 280610\n",
      "2024-08-02 23:59:43.478 | DEBUG    | pybuda.ttdevice:forward:906 - Starting forward on TTDevice 'tt_device_0'\n",
      "2024-08-02 23:59:43.478 | DEBUG    | pybuda.backend:feeder_thread_main:171 - Run feeder thread cmd: fwd\n",
      "2024-08-02 23:59:43.479 | DEBUG    | pybuda.backend:read_queues:345 - Reading output queue asl_model.output_add_636\n",
      "2024-08-02 23:59:43.481 | DEBUG    | pybuda.device_connector:pusher_thread_main:163 - Pusher thread pushing tensors\n",
      "2024-08-02 23:59:43.481 | DEBUG    | pybuda.backend:push_to_queues:452 - Pushing to queue pixel_values\n",
      "2024-08-02 23:59:43.541 | DEBUG    | pybuda.backend:read_queues:415 - Done reading queues\n",
      "2024-08-02 23:59:43.542 | DEBUG    | pybuda.backend:pop_queues:421 - Popping from queue asl_model.output_add_636\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_tensor = setup_image(dataset['image'][0])\n",
    "tt0.push_to_inputs((image_tensor,))\n",
    "# output = pybuda_module.run(input_tensor)  # executes compilation (if first time) + runtime\n",
    "output_q = pybuda.run_inference()\n",
    "# print('output: ', output)\n",
    "output = output_q.get() # get last value from output queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12.0000,  0.2148,  0.5625,  0.4688,  2.8906,  0.6445, -0.5430, -0.4180,\n",
       "         -0.3945,  0.1621, -1.3828,  1.3281, -0.7812, -1.0391, -1.9688, -0.1777,\n",
       "         -1.5234,  0.8789, -2.1406, -0.0403, -0.7500, -1.5703, -1.4922, -0.3027,\n",
       "         -1.5781, -2.1875]], dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].value().argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pybuda.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt0.remove_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybuda\n",
    "import torch\n",
    "\n",
    "\n",
    "# Sample PyTorch module\n",
    "class PyTorchTestModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights1 = torch.nn.Parameter(torch.rand(32, 32), requires_grad=True)\n",
    "        self.weights2 = torch.nn.Parameter(torch.rand(32, 32), requires_grad=True)\n",
    "    def forward(self, act1, act2):\n",
    "        m1 = torch.matmul(act1, self.weights1)\n",
    "        m2 = torch.matmul(act2, self.weights2)\n",
    "        return m1 + m2, m1\n",
    "\n",
    "\n",
    "def test_module_direct_pytorch():\n",
    "    input1 = torch.rand(4, 32, 32)\n",
    "    input2 = torch.rand(4, 32, 32)\n",
    "    # Run single inference pass on a PyTorch module, using a wrapper to convert to PyBuda first\n",
    "    output = pybuda.PyTorchModule(\"direct_pt\", PyTorchTestModule()).run(input1, input2)\n",
    "    print(output)\n",
    "    print(\"PyBuda installation was a success!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_module_direct_pytorch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
